# ğŸ”„ Switching to Sentence Transformers

## âœ… What Changed

### 1. **Added Sentence Transformers Support**
- âœ… New embedding provider option: `sentence_transformers`
- âœ… Local, free embeddings (no API costs!)
- âœ… Fast and works offline

### 2. **Configuration Updated**
- âœ… Added `EMBEDDING_PROVIDER` setting
- âœ… Added `SENTENCE_TRANSFORMER_MODEL` setting
- âœ… Auto-detects embedding dimensions

### 3. **Dependencies Installed**
- âœ… `sentence-transformers` package
- âœ… `torch` (PyTorch) - required dependency

---

## ğŸ“ Update Your `.env` File

Add these lines to `backend/.env`:

```env
# Embedding Provider (choose one)
EMBEDDING_PROVIDER=sentence_transformers

# Sentence Transformer Model
# Options:
#   - all-MiniLM-L6-v2 (384 dimensions, fast, good quality)
#   - all-mpnet-base-v2 (768 dimensions, better quality, slower)
#   - sentence-transformers/all-MiniLM-L12-v2 (384 dimensions)
SENTENCE_TRANSFORMER_MODEL=all-MiniLM-L6-v2
```

---

## ğŸ¯ Model Options

### Recommended Models:

1. **`all-MiniLM-L6-v2`** (Default - Recommended)
   - Dimensions: 384
   - Speed: âš¡ Very Fast
   - Quality: âœ… Good
   - Size: Small (~80MB)
   - **Best for:** Most use cases

2. **`all-mpnet-base-v2`**
   - Dimensions: 768
   - Speed: ğŸ¢ Slower
   - Quality: â­ Excellent
   - Size: Large (~420MB)
   - **Best for:** When quality is critical

3. **`sentence-transformers/all-MiniLM-L12-v2`**
   - Dimensions: 384
   - Speed: âš¡ Fast
   - Quality: âœ… Very Good
   - Size: Medium (~130MB)
   - **Best for:** Balance of speed and quality

---

## ğŸ”„ How to Switch

### Step 1: Update `.env`
```env
EMBEDDING_PROVIDER=sentence_transformers
SENTENCE_TRANSFORMER_MODEL=all-MiniLM-L6-v2
```

### Step 2: Restart Backend
The backend will:
- Load the Sentence Transformer model on startup
- Auto-detect embedding dimensions
- Use local embeddings (no API calls!)

### Step 3: Re-ingest Documents
Since embedding dimensions changed, you need to re-ingest:
```bash
# Delete old FAISS index
rm backend/data/faiss/index.faiss
rm backend/data/faiss/metadata.jsonl

# Re-ingest documents
python backend/scripts/bulk_ingest_documents.py
```

---

## ğŸ’° Cost Comparison

### OpenAI Embeddings:
- ğŸ’° **Cost:** ~$0.0001 per 1K tokens
- ğŸŒ **Requires:** Internet + API key
- âš¡ **Speed:** Fast (API call)

### Sentence Transformers:
- âœ… **Cost:** FREE (runs locally)
- ğŸ  **Requires:** Just your computer
- âš¡ **Speed:** Very fast (local processing)

---

## ğŸ“Š Performance

**Sentence Transformers:**
- âœ… No API rate limits
- âœ… Works offline
- âœ… No costs
- âœ… Fast batch processing
- âœ… Good quality for most tasks

**OpenAI Embeddings:**
- âœ… Slightly better quality
- âŒ Costs money
- âŒ Requires internet
- âŒ API rate limits

---

## ğŸ¯ Recommendation

**For your use case (local development):**
- âœ… **Use Sentence Transformers** (`all-MiniLM-L6-v2`)
- âœ… Free, fast, works offline
- âœ… Perfect quality for legal document search

---

## âœ… After Switching

1. **Update `.env`** with `EMBEDDING_PROVIDER=sentence_transformers`
2. **Restart backend** (to load new model)
3. **Re-ingest documents** (new embeddings)
4. **Test chat** - should work perfectly!

---

**Sentence Transformers is installed and ready! Just update `.env` and restart!** ğŸš€

